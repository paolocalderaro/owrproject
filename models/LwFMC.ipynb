{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LwFMC.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"XNsHBRAZaHfY"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import BCEWithLogitsLoss\n","from torch.backends import cudnn\n","\n","import numpy as np\n","from copy import deepcopy\n","\n","class LWF():\n","    def __init__(self, device, net, old_net, criterion, optimizer, scheduler,\n","                 train_dataloader, val_dataloader, test_dataloader, num_classes=10):\n","\n","        self.device = device\n","\n","        self.net = net\n","        self.best_net = self.net\n","        self.old_net = old_net  # None for first ten classes\n","\n","        # BCE formulation\n","        # Let x = logits, z = labels. The logistic loss is:\n","        # z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n","        self.criterion = BCEWithLogitsLoss()\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","\n","        self.train_dataloader = train_dataloader\n","        self.val_dataloader = val_dataloader\n","        self.test_dataloader = test_dataloader\n","\n","        # can be incremented ouitside methods in the main, or inside methods\n","        self.num_classes = num_classes\n","        self.order = np.arange(100)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","\n","        \n","\n","    def warm_up():\n","        pass\n","\n","    def increment_classes(self, n=10):\n","        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n","\n","        in_features = self.net.fc.in_features  \n","        out_features = self.net.fc.out_features \n","        weight = self.net.fc.weight.data\n","\n","        self.net.fc = nn.Linear(in_features, out_features+n)\n","        self.net.fc.weight.data[:out_features] = weight\n","\n","    def to_onehot(self, targets):\n","        \"\"\"Convert targets to one-hot encoding (for BCE loss).\n","        Args:\n","            targets: dataloader.dataset.targets of the new task images\n","        \"\"\"\n","\n","        one_hot_targets = torch.eye(self.num_classes)[targets]\n","\n","        return one_hot_targets.to(self.device)\n","\n","    def do_first_batch(self, batch, labels):\n","        batch = batch.to(self.device)\n","        labels = labels.to(self.device)  # new classes labels\n","\n","        # Zero-ing the gradients\n","        self.optimizer.zero_grad()\n","\n","        # One hot encoding of new task labels\n","        one_hot_labels = self.to_onehot(labels)  \n","\n","        # New net forward pass\n","        outputs = self.net(batch)\n","\n","        # BCE Loss with sigmoids over outputs\n","        loss = self.criterion(outputs, one_hot_labels)\n","\n","        # Get predictions\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        # Accuracy over NEW IMAGES, not over all images\n","        running_corrects = \\\n","            torch.sum(preds == labels.data).data.item()\n","\n","        # Backward pass: computes gradients\n","        loss.backward()\n","\n","        self.optimizer.step()\n","\n","        return loss, running_corrects\n","\n","    def do_batch(self, batch, labels):\n","        batch = batch.to(self.device)\n","        labels = labels.to(self.device)  # new classes labels\n","\n","        # Zero-ing the gradients\n","        self.optimizer.zero_grad()\n","\n","        # One hot encoding of new task labels\n","        # Size = [128, n_classes] will be sliced as [:, :self.num_classes-10]\n","        one_hot_labels = self.to_onehot(labels)\n","\n","        if self.counter == 0:\n","          print(\"Size 1H labels: \", one_hot_labels.size())\n","        new_classes = (\n","            self.order[range(self.num_classes-10, self.num_classes)]).astype(np.int32)\n","        one_hot_labels = torch.stack(\n","            [one_hot_labels[:, i] for i in new_classes], axis=1) \n","\n","        if self.counter == 0:\n","          print(\"Size 1H labels: \", one_hot_labels.size())\n","\n","        \n","        old_outputs = self.sigmoid(self.old_net(batch))  \n","        if self.counter == 0:\n","          print(\"Size old_outputs : \", old_outputs.size())\n","\n","        old_classes = (self.order[range(self.num_classes-10)]).astype(np.int32)\n","        old_outputs = torch.stack([old_outputs[:, i]               \n","                                   for i in old_classes], axis=1)\n","        if self.counter == 0:\n","          print(\"Size old_outputs : \", old_outputs.size())\n","\n","        # Combine new and old class targets\n","        targets = torch.cat((old_outputs, one_hot_labels), 1) \n","\n","        # New net forward pass\n","        outputs = self.net(batch)\n","        out_classes = (self.order[range(self.num_classes)]).astype(np.int32)\n","        outputs = torch.stack([outputs[:, i] for i in out_classes], axis=1)\n","\n","        # BCE Loss \n","        loss = self.criterion(outputs, targets)\n","\n","        # Get predictions\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        # Accuracy over NEW IMAGES, not over all images\n","        running_corrects = \\\n","            torch.sum(preds == labels.data).data.item()\n","\n","        # Backward pass: computes gradients\n","        loss.backward()\n","\n","        self.optimizer.step()\n","\n","        self.counter += 1\n","\n","        return loss, running_corrects\n","\n","    def do_epoch(self, current_epoch): \n","        self.net.train()\n","\n","        running_train_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n","\n","        for images, labels in self.train_dataloader:\n","\n","            if self.num_classes == 10: # <-- unica differenza rispetto al manager\n","                loss, corrects = self.do_first_batch(images, labels)\n","            else:\n","                loss, corrects = self.do_batch(images, labels)\n","\n","            running_train_loss += loss.item()\n","            running_corrects += corrects\n","            total += labels.size(0)\n","            batch_idx += 1\n","\n","        self.scheduler.step()\n","\n","        # Calculate average scores\n","        train_loss = running_train_loss / batch_idx  # Average over all batches\n","        train_accuracy = running_corrects / float(total)  # Average over all samples\n","\n","        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n","\n","        return train_loss, train_accuracy\n","\n","    def train(self, num_epochs):\n","        \"\"\"Train the network for a specified number of epochs, and save\n","        the best performing model on the validation set.\n","        Args:\n","            num_epochs (int): number of epochs for training the network.\n","        Returns:\n","            train_loss: loss computed on the last epoch\n","            train_accuracy: accuracy computed on the last epoch\n","            val_loss: average loss on the validation set of the last epoch\n","            val_accuracy: accuracy on the validation set of the last epoch\n","        \"\"\"\n","\n","        self.net = self.net.to(self.device)\n","        if self.old_net != None:\n","            self.old_net = self.old_net.to(self.device)\n","            self.old_net.train(False) \n","\n","        cudnn.benchmark  # Calling this optimizes runtime\n","\n","        self.best_loss = float(\"inf\")\n","        self.best_epoch = 0\n","\n","        for epoch in range(num_epochs):\n","            # Run an epoch (start counting form 1)\n","            train_loss, train_accuracy = self.do_epoch(epoch+1)\n","\n","            # Validate after each epoch\n","            val_loss, val_accuracy = self.validate()\n","\n","            # Best validation model\n","            if val_loss < self.best_loss:\n","                self.best_loss = val_loss\n","                self.best_net = deepcopy(self.net)\n","                self.best_epoch = epoch\n","                print(\"Best model updated\")\n","\n","            print(\"\")\n","\n","        return train_loss, train_accuracy, val_loss, val_accuracy\n","\n","    def validate(self):\n","        \"\"\"Validate the model.\n","        Returns:\n","            val_loss: average loss function computed on the network outputs\n","                of the validation set (val_dataloader).\n","            val_accuracy: accuracy computed on the validation set.\n","        \"\"\"\n","\n","        self.net.train(False)\n","\n","        running_val_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        for batch, labels in self.val_dataloader:\n","            batch = batch.to(self.device)\n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # One hot encoding of new task labels         \n","            one_hot_labels = self.to_onehot(labels)\n","            new_classes = (\n","                self.order[range(self.num_classes-10, self.num_classes)]).astype(np.int32)\n","            one_hot_labels = torch.stack(\n","                [one_hot_labels[:, i] for i in new_classes], axis=1)\n","           \n","            if self.num_classes > 10:\n","                # Old net forward pass\n","                old_outputs = self.sigmoid(\n","                    self.old_net(batch))  \n","                old_classes = (\n","                    self.order[range(self.num_classes-10)]).astype(np.int32)\n","                old_outputs = torch.stack(\n","                    [old_outputs[:, i] for i in old_classes], axis=1)\n","\n","                # Combine new and old class targets\n","                targets = torch.cat((old_outputs, one_hot_labels), 1)\n","\n","            else:\n","                targets = one_hot_labels\n","\n","            # New net forward pass\n","            outputs = self.net(batch)\n","            out_classes = (\n","                self.order[range(self.num_classes)]).astype(np.int32)\n","            outputs = torch.stack([outputs[:, i] for i in out_classes], axis=1)\n","\n","            # BCE Loss \n","            loss = self.criterion(outputs, targets)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update the number of correctly classified validation samples\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","            running_val_loss += loss.item()\n","\n","            batch_idx += 1\n","\n","        # Calcuate scores\n","        val_loss = running_val_loss / batch_idx\n","        val_accuracy = running_corrects / float(total)\n","\n","        print(\n","            f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n","\n","        return val_loss, val_accuracy\n","\n","    def test(self):\n","        \"\"\"Test the model.\n","        Returns:\n","            accuracy (float): accuracy of the model on the test set\n","        \"\"\"\n","\n","        self.best_net.train(False)  # Set Network to evaluation mode\n","\n","        running_corrects = 0\n","        total = 0\n","\n","        all_preds = torch.tensor([])  # to store all predictions\n","        all_preds = all_preds.type(torch.LongTensor)\n","        all_targets = torch.tensor([])\n","        all_targets = all_targets.type(torch.LongTensor)\n","\n","        for images, labels in self.test_dataloader:\n","            images = images.to(self.device)\n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # Forward Pass\n","            outputs = self.best_net(images)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update Corrects\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","            all_targets = torch.cat(\n","                (all_targets.to(self.device), labels.to(self.device)), dim=0\n","            )\n","\n","            # Append batch predictions\n","            all_preds = torch.cat(\n","                (all_preds.to(self.device), preds.to(self.device)), dim=0\n","            )\n","\n","        # Calculate accuracy\n","        accuracy = running_corrects / float(total)\n","\n","        print(f\"Test accuracy: {accuracy}\")\n","\n","        return accuracy, all_targets, all_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bEU4bPuGqLJ"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import BCEWithLogitsLoss\n","from torch.backends import cudnn\n","\n","import numpy as np\n","from copy import deepcopy\n","\n","class LWFoptimized():\n","    def __init__(self, device, net, old_net, criterion, optimizer, scheduler,\n","                 train_dataloader, val_dataloader, test_dataloader, num_classes=10):\n","\n","        self.device = device\n","\n","        self.net = net\n","        self.best_net = self.net\n","        self.old_net = old_net  # None for first ten classes\n","\n","        # BCE formulation\n","        # Let x = logits, z = labels. The logistic loss is:\n","        # z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n","        self.criterion = BCEWithLogitsLoss()\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","\n","        self.train_dataloader = train_dataloader\n","        self.val_dataloader = val_dataloader\n","        self.test_dataloader = test_dataloader\n","\n","        # can be incremented ouitside methods in the main, or inside methods\n","        self.num_classes = num_classes\n","        self.sigmoid = nn.Sigmoid()\n","\n","\n","    def increment_classes(self, n=10):\n","        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n","\n","        in_features = self.net.fc.in_features  # size of each input sample\n","        out_features = self.net.fc.out_features  # size of each output sample\n","        weight = self.net.fc.weight.data\n","\n","        self.net.fc = nn.Linear(in_features, out_features+n)\n","        self.net.fc.weight.data[:out_features] = weight\n","\n","    def to_onehot(self, targets):\n","        \"\"\"Convert targets to one-hot encoding (for BCE loss).\n","        Args:\n","            targets: dataloader.dataset.targets of the new task images\n","        \"\"\"\n","\n","        one_hot_targets = torch.eye(self.num_classes)[targets]\n","\n","        return one_hot_targets.to(self.device)\n","\n","    def do_first_batch(self, batch, labels):\n","        batch = batch.to(self.device)\n","        labels = labels.to(self.device)  # new classes labels\n","\n","        # Zero-ing the gradients\n","        self.optimizer.zero_grad()\n","\n","        # One hot encoding of new task labels\n","        one_hot_labels = self.to_onehot(labels)  # Size = [128, 10]\n","\n","        # New net forward pass\n","        outputs = self.net(batch)\n","\n","        # BCE Loss with sigmoids over outputs\n","        loss = self.criterion(outputs, one_hot_labels)\n","\n","        # Get predictions\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        # Accuracy over NEW IMAGES, not over all images\n","        running_corrects = \\\n","            torch.sum(preds == labels.data).data.item()\n","\n","        # Backward pass: computes gradients\n","        loss.backward()\n","\n","        self.optimizer.step()\n","\n","        return loss, running_corrects\n","\n","    def do_batch(self, batch, labels):\n","        batch = batch.to(self.device)\n","        labels = labels.to(self.device)  # new classes labels\n","\n","        # Zero-ing the gradients\n","        self.optimizer.zero_grad()\n","\n","        # One hot encoding of new task labels\n","        one_hot_labels = self.to_onehot(labels)\n","        one_hot_labels = one_hot_labels[:, -10:] \n","\n","        old_outputs = self.sigmoid(self.old_net(batch))  \n","\n","        # Combine new and old class targets\n","        targets = torch.cat((old_outputs, one_hot_labels), 1) \n","\n","        # New net forward pass\n","        outputs = self.net(batch)\n","\n","\n","        # BCE Loss \n","        loss = self.criterion(outputs, targets)\n","\n","        # Get predictions\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        # Accuracy over NEW IMAGES, not over all images\n","        running_corrects = \\\n","            torch.sum(preds == labels.data).data.item()\n","\n","        # Backward pass: computes gradients\n","        loss.backward()\n","\n","        self.optimizer.step()\n","\n","\n","        return loss, running_corrects\n","\n","    def do_epoch(self, current_epoch): \n","        self.net.train()\n","\n","        running_train_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n","\n","        for images, labels in self.train_dataloader:\n","\n","            if self.num_classes == 10: \n","                loss, corrects = self.do_first_batch(images, labels)\n","            else:\n","                loss, corrects = self.do_batch(images, labels)\n","\n","            running_train_loss += loss.item()\n","            running_corrects += corrects\n","            total += labels.size(0)\n","            batch_idx += 1\n","\n","        self.scheduler.step()\n","\n","        # Calculate average scores\n","        train_loss = running_train_loss / batch_idx  # Average over all batches\n","        train_accuracy = running_corrects / float(total)  # Average over all samples\n","\n","        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n","\n","        return train_loss, train_accuracy\n","\n","    def train(self, num_epochs):\n","        \"\"\"Train the network for a specified number of epochs, and save\n","        the best performing model on the validation set.\n","        Args:\n","            num_epochs (int): number of epochs for training the network.\n","        Returns:\n","            train_loss: loss computed on the last epoch\n","            train_accuracy: accuracy computed on the last epoch\n","            val_loss: average loss on the validation set of the last epoch\n","            val_accuracy: accuracy on the validation set of the last epoch\n","        \"\"\"\n","\n","        self.net = self.net.to(self.device)\n","        if self.old_net != None:\n","            self.old_net = self.old_net.to(self.device)\n","            self.old_net.train(False) \n","\n","        cudnn.benchmark  # Calling this optimizes runtime\n","\n","        self.best_loss = float(\"inf\")\n","        self.best_epoch = 0\n","\n","        for epoch in range(num_epochs):\n","            # Run an epoch (start counting form 1)\n","            train_loss, train_accuracy = self.do_epoch(epoch+1)\n","\n","            # Validate after each epoch\n","            val_loss, val_accuracy = self.validate()\n","\n","            # Best validation model\n","            if val_loss < self.best_loss:\n","                self.best_loss = val_loss\n","                self.best_net = deepcopy(self.net)\n","                self.best_epoch = epoch\n","                print(\"Best model updated\")\n","\n","            print(\"\")\n","\n","        return train_loss, train_accuracy, val_loss, val_accuracy\n","\n","    def validate(self):\n","        \"\"\"Validate the model.\n","        Returns:\n","            val_loss: average loss function computed on the network outputs\n","                of the validation set (val_dataloader).\n","            val_accuracy: accuracy computed on the validation set.\n","        \"\"\"\n","\n","        self.net.train(False)\n","\n","        running_val_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        for batch, labels in self.val_dataloader:\n","            batch = batch.to(self.device)\n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # One hot encoding of new task labels \n","            \n","            one_hot_labels = self.to_onehot(labels)\n","            one_hot_labels = one_hot_labels[:,-10:]       \n","\n","            if self.num_classes > 10:\n","                # Old net forward pass\n","                old_outputs = self.sigmoid(self.old_net(batch))  \n","\n","\n","                # Combine new and old class targets\n","                targets = torch.cat((old_outputs, one_hot_labels), 1)\n","\n","            else:\n","                targets = one_hot_labels\n","\n","            # New net forward pass          \n","            outputs = self.net(batch)\n","\n","\n","            # BCE Loss with sigmoids over outputs \n","            loss = self.criterion(outputs, targets)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update the number of correctly classified validation samples\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","            running_val_loss += loss.item()\n","\n","            batch_idx += 1\n","\n","        # Calcuate scores\n","        val_loss = running_val_loss / batch_idx\n","        val_accuracy = running_corrects / float(total)\n","\n","        print(\n","            f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n","\n","        return val_loss, val_accuracy\n","\n","    def test(self):\n","        \"\"\"Test the model.\n","        Returns:\n","            accuracy (float): accuracy of the model on the test set\n","        \"\"\"\n","\n","        self.best_net.train(False)  # Set Network to evaluation mode\n","\n","        running_corrects = 0\n","        total = 0\n","\n","        all_preds = torch.tensor([])  # to store all predictions\n","        all_preds = all_preds.type(torch.LongTensor)\n","        all_targets = torch.tensor([])\n","        all_targets = all_targets.type(torch.LongTensor)\n","\n","        for images, labels in self.test_dataloader:\n","            images = images.to(self.device)\n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # Forward Pass\n","            outputs = self.best_net(images)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update Corrects\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","            all_targets = torch.cat(\n","                (all_targets.to(self.device), labels.to(self.device)), dim=0\n","            )\n","\n","            # Append batch predictions\n","            all_preds = torch.cat(\n","                (all_preds.to(self.device), preds.to(self.device)), dim=0\n","            )\n","\n","        # Calculate accuracy\n","        accuracy = running_corrects / float(total)\n","\n","        print(f\"Test accuracy: {accuracy}\")\n","\n","        return accuracy, all_targets, all_preds"],"execution_count":null,"outputs":[]}]}